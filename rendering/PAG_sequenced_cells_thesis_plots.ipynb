{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising PAG neurons in CCF space\n",
    "In this notebook we will load the .csv file containing the metadata from our PAG_scRNAseq project and use the CCF coordinates obtained after registration with Sharp-Track to visualise our sequenced cells with Brainrender. We will also write some code to generate some figures for the thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | Import packages and set defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainrender\n",
    "from brainrender import Scene, Animation\n",
    "from brainrender.actors import Points\n",
    "from vedo import settings as vsettings\n",
    "from brainrender.video import VideoMaker\n",
    "import pandas as pd # used to load the cwv\n",
    "import numpy as np # used to set beginning and end of a custom slice\n",
    "from vedo import embedWindow, Plotter, show  # <- this will be used to render an embedded scene \n",
    "\n",
    "\n",
    "# // DEFAULT SETTINGS //\n",
    "# You can see all the default settings here: https://github.com/brainglobe/brainrender/blob/19c63b97a34336898871d66fb24484e8a55d4fa7/brainrender/settings.py\n",
    "\n",
    "# --------------------------- brainrender settings --------------------------- #\n",
    "# Change some of the default settings\n",
    "brainrender.settings.BACKGROUND_COLOR = \"white\" # color of the background window (defaults to \"white\", try \"blackboard\")\n",
    "brainrender.settings.DEFAULT_ATLAS = \"allen_mouse_25um\"  # default atlas\n",
    "brainrender.settings.DEFAULT_CAMERA = \"three_quarters\"  # Default camera settings (orientation etc. see brainrender.camera.py)\n",
    "brainrender.settings.INTERACTIVE = False  # rendering interactive ?\n",
    "brainrender.settings.LW = 2  # e.g. for silhouettes\n",
    "brainrender.settings.ROOT_COLOR = [0.4, 0.4, 0.4]  # color of the overall brain model's actor (defaults to [0.8, 0.8, 0.8])\n",
    "brainrender.settings.ROOT_ALPHA = 0.2  # transparency of the overall brain model's actor (defaults to 0.2)\n",
    "brainrender.settings.SCREENSHOT_SCALE = 1  # values >1 yield higher resolution screenshots\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\"  # affects the look of rendered brain regions, values can be: [\"metallic\", \"plastic\", \"shiny\", \"glossy\", \"cartoon\"] and can be changed in interactive mode\n",
    "brainrender.settings.SHOW_AXES = False\n",
    "brainrender.settings.WHOLE_SCREEN = True  # If true render window is full screen\n",
    "brainrender.settings.OFFSCREEN = False\n",
    "\n",
    "# ------------------------------- vedo settings ------------------------------ #\n",
    "# For transparent background with screenshots\n",
    "vsettings.screenshotTransparentBackground = True  # vedo for transparent bg\n",
    "vsettings.useFXAA = False  # This needs to be false for transparent bg\n",
    "\n",
    "\n",
    "# // SET PARAMETERS //\n",
    "# Save folder\n",
    "save_folder = r\"D:\\Dropbox (UCL)\\Project_transcriptomics\\analysis\\PAG_scRNAseq_brainrender\\output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 | Check atlas availability\n",
    "Brainrender integrates several atlases that can be used to visualise and explore brain anatomy. We can check which atlases are available, take a look at the ones we have already downloaded, and render a basic scene with the axis to get an idea of the overall picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to get a list of the available atlases:\n",
    "from bg_atlasapi import show_atlases\n",
    "show_atlases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dimensions of an atlas:\n",
    "from bg_atlasapi.bg_atlas import BrainGlobeAtlas\n",
    "atlas = BrainGlobeAtlas(\"allen_mouse_25um\")\n",
    "reference_image = atlas.reference\n",
    "print(reference_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, among the atlases we can use for mouse data:\n",
    "* allen_mouse_10um_v1.2 - Volume dimension of \\[AP, SI, LR\\] equivalent to \\[1320, 800, 1140\\]\n",
    "* allen_mouse_25um_v1.2 - Volume dimension of \\[AP, SI, LR\\] equivalent to \\[528, 320, 456\\] (default atlas)\n",
    "* kim_mouse_10um_v1.0 - Volume dimension of \\[AP, SI, LR\\] equivalent to \\[1320, 800, 1140\\]\n",
    "* kim_unified_25um_v1.0 - Volume dimension of \\[AP, SI, LR\\] equivalent to \\[528, 320, 456\\]\n",
    "* kim_unified_50um_v1.0 - Volume dimension of \\[AP, SI, LR\\] equivalent to \\[264, 160, 228\\]\n",
    "* osten_mouse_10um_v1.1 - Volume dimension of \\[AP, SI, LR\\] equivalent to \\[1320, 800, 1140\\]\n",
    "\n",
    "The CCF coordinates we obtained from Sharp-Track are at 10um resolution, with a Volume dimension of \\[AP, SI, LR\\] equivalent to \\[1320, 800, 1140\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "\n",
    "# Create a scene with the with the preferred atlas and check the dimensions\n",
    "brainrender.settings.SHOW_AXES = True\n",
    "scene = Scene(root = True, atlas_name = 'allen_mouse_25um', inset = False, title = 'allen_mouse_25um', screenshots_folder = save_folder, plotter = None)\n",
    "\n",
    "scene.render(interactive = True, camera = \"sagittal\", zoom = 1) # make sure to press 'Esc' to close not 'q' or kernel dies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | Load metadata including CCF coordinates\n",
    "Other options to load registered points include `add_cells_from_file` and `get_probe_points_from_sharptrack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pag_data = pd.read_csv(\"D:\\\\Dropbox (UCL - SWC)\\\\Project_transcriptomics\\\\analysis\\\\PAG_scRNAseq_brainrender\\\\PAG_scRNAseq_metadata_211018.csv\")\n",
    "\n",
    "# Look at the first 5 rows of the metadata\n",
    "pag_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all column names in data\n",
    "pag_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 | Scaling up coordinates\n",
    "The CCF coordinates were obtained by registering images to the Allen Brain Atlas using Sharp-Track (see Shamash et al. bioRxiv 2018 and https://github.com/cortex-lab/allenCCF), which yields coordinates at a resolution of 10 micrometers. In the Allen Brain Atlas, a point at coordinates \\[1, 0, 0\\] is at 10um from the origin (in other words, 1 unit of the atlas space equals 10um). However, BrainRender's space is at 1um resolution, so the first thing we need to do is to scale up the coordinate values by 10 to get them to match correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the CCF coordinates for each cell\n",
    "pag_data[[\"cell.id\", \"cell.type\", \"PAG.area\", \"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale up data\n",
    "sharptrack_to_brainrender_scale_factor = 10 # Sharp-Track uses a 10um reference atlas so the coordinates need to be scaled to match brainrender's\n",
    "\n",
    "pag_data[\"CCF.AllenAP\"] *= sharptrack_to_brainrender_scale_factor\n",
    "pag_data[\"CCF.AllenDV\"] *= sharptrack_to_brainrender_scale_factor\n",
    "pag_data[\"CCF.AllenML\"] *= sharptrack_to_brainrender_scale_factor\n",
    "\n",
    "pag_data[[\"cell.id\", \"cell.type\", \"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 | Rendering cells with Brainrender\n",
    "Now that we have the coordinates at the right scale, we can render our cells in Brainrender and colour them according to any metadata we want. We will prepare different renderings in each of the following code chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 | Selecting a subset of cells\n",
    "We can first take a look at how to use the metadata to select subsets of cells. This will be useful to either render just some of the cells, or to color cells based on some metadata info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can subset cells using any criteria we want. For instance, let's keep cells coming from each hemisphere in separate variables:\n",
    "cells_hemisphere_right = pag_data.loc[pag_data[\"PAG.hemisphere\"] == \"right\"]\n",
    "cells_hemisphere_left = pag_data.loc[pag_data[\"PAG.hemisphere\"] == \"left\"]\n",
    "cells_hemisphere_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use multiple criteria at the same time, such as hemisphere and cell type:\n",
    "vgat_cells_hemisphere_left = pag_data.loc[(pag_data[\"PAG.hemisphere\"] == \"left\")&(pag_data[\"cell.type\"] == \"VGAT\")]\n",
    "vgat_cells_hemisphere_left.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now render a scene adding each subset independently, so we can tweak variables such as color or size separately. However, brainrender requires an array of 3 values as coordinates, so we need to get the values out instead of subsetting the dataframe and providing it as input when creating a scene: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "cells_hemisphere_right[column_names].head().values # brainrender needs a numpy array as coordinates. Without the .values we get a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can render a scene and color the cells on the right and left hemisphere differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "brainrender.settings.SHOW_AXES = False # Set this back to False\n",
    "\n",
    "# Create a variable containing the XYZ coordinates of the cells.\n",
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "\n",
    "# // CREATE SCENE //\n",
    "scene = Scene(root = True, atlas_name = 'allen_mouse_25um', inset = False, title = 'Aspirated Cells', screenshots_folder = save_folder, plotter = None)\n",
    "\n",
    "# // ADD REGIONS AND CELLS//\n",
    "scene.add_brain_region(\"PAG\", alpha = 0.1, color = \"darkgoldenrod\", silhouette = None, hemisphere = \"both\")\n",
    "scene.add(Points(cells_hemisphere_right[column_names].values, name = \"right hemisphere\", colors = \"salmon\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(cells_hemisphere_left[column_names].values, name = \"left hemisphere\", colors = \"skyblue\", alpha = 1, radius = 20, res = 16))\n",
    "\n",
    "# // RENDER INTERACTIVELY //\n",
    "# Render interactively. You can press \"s\" to take a screenshot\n",
    "scene.render(interactive = True, camera = \"sagittal\", zoom = 1) # make sure to press 'Esc' to close not 'q' or kernel dies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 | Rendering VGAT and VGluT2 cells for Chapter 2\n",
    "We can follow the strategy above and assign each cell type to a different variable and render them separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 | Plot brain, PAG, and aspirated cells\n",
    "\n",
    "We have increased the screenshot resoolution, changed the save folder, and increased the radius of the cells so they are visible. \n",
    "\n",
    "We will use \"plastic\" as shader style in this overview figure, have the axes so we can draw a scale bar, and render using the Top camera and a 1.1x zoom.\n",
    "\n",
    "Once rendered, save a screenshot by pressing \"s\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "brainrender.settings.SHOW_AXES = True\n",
    "brainrender.settings.SCREENSHOT_SCALE = 10 # values >1 yield higher resolution screenshots\n",
    "brainrender.settings.SHADER_STYLE = \"plastic\" # affects the look of rendered brain regions, values can be: [\"metallic\", \"plastic\", \"shiny\", \"glossy\", \"cartoon\"] and can be changed in interactive mode\n",
    "brainrender.settings.ROOT_COLOR = [0.4, 0.4, 0.4] # color of the overall brain model's actor (defaults to [0.8, 0.8, 0.8])\n",
    "brainrender.settings.ROOT_ALPHA = 0.2 # transparency of the overall brain model's actor (defaults to 0.2)\n",
    "save_folder_thesis = r\"D:\\Dropbox (UCL)\\Project_transcriptomics\\analysis\\PAG_scRNAseq_brainrender\\output\\figures_thesis_chapter_2\"\n",
    "\n",
    "# Create a variable containing the XYZ coordinates of the cells.\n",
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "\n",
    "# Color cells according to whether they are excitatory or inhibitory:\n",
    "vgat_cells = pag_data.loc[pag_data[\"cell.type\"] == \"VGAT\"]\n",
    "vglut2_cells =  pag_data.loc[pag_data[\"cell.type\"] == \"VGluT2\"]\n",
    "\n",
    "# // CREATE SCENE //\n",
    "scene = Scene(root = True, atlas_name = 'allen_mouse_25um', inset = False, title = None, screenshots_folder = save_folder_thesis, plotter = None)\n",
    "\n",
    "# // ADD REGIONS AND CELLS//\n",
    "scene.add_brain_region(\"PAG\", alpha = 0.2, color = \"darkgoldenrod\", silhouette = None, hemisphere = \"both\")\n",
    "#scene.add_brain_region(\"SCm\", alpha = 0.1, color = \"olivedrab\", silhouette = None, hemisphere = \"both\")\n",
    "scene.add(Points(vgat_cells[column_names].values, name = \"vgat\", colors = \"#FF8080\", alpha = 1, radius = 30, res = 16)) # colour is #FF8080 in figures, but salmon is the same\n",
    "scene.add(Points(vglut2_cells[column_names].values, name = \"vglut2\", colors = \"#0F99B2\", alpha = 1, radius = 30, res = 16)) # colour is #0F99B2 in figures, but skyblue looks good here\n",
    "\n",
    "# // RENDER INTERACTIVELY //\n",
    "# Render interactively. You can press \"s\" to take a screenshot\n",
    "scene.render(interactive = True, camera = \"top\", zoom = 1.1) # cameras can be \"sagittal\", \"sagittal2\", \"frontal\", \"top\", \"top_side\", \"three_quarters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 | Plot PAG and aspirated cells at different angles\n",
    "\n",
    "Now we want to render and save some images in which we zoom into the PAG to visualise the registered cells. We can color by cell type or by PAG subdivision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colouring cells by cell_type (VGAT or VGluT2), we will save the following screenshots:\n",
    "* Axes True, Zoom 4, Top Camera\n",
    "* Axes False, Zoom 4, Top Camera\n",
    "* Axes False, Zoom 4, Sagittal Camera\n",
    "* Axes False, Zoom 4, Three quarters Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "brainrender.settings.SHOW_AXES = False\n",
    "brainrender.settings.SCREENSHOT_SCALE = 10 # values >1 yield higher resolution screenshots\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\" # affects the look of rendered brain regions, values can be: [\"metallic\", \"plastic\", \"shiny\", \"glossy\", \"cartoon\"] and can be changed in interactive mode\n",
    "brainrender.settings.ROOT_COLOR = [0.4, 0.4, 0.4] # color of the overall brain model's actor (defaults to [0.8, 0.8, 0.8])\n",
    "brainrender.settings.ROOT_ALPHA = 0.2 # transparency of the overall brain model's actor (defaults to 0.2)\n",
    "save_folder_thesis = r\"D:\\Dropbox (UCL)\\Project_transcriptomics\\analysis\\PAG_scRNAseq_brainrender\\output\\figures_thesis_chapter_2\"\n",
    "\n",
    "# Create a variable containing the XYZ coordinates of the cells.\n",
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "\n",
    "# Color cells according to whether they are excitatory or inhibitory:\n",
    "vgat_cells = pag_data.loc[pag_data[\"cell.type\"] == \"VGAT\"]\n",
    "vglut2_cells =  pag_data.loc[pag_data[\"cell.type\"] == \"VGluT2\"]\n",
    "\n",
    "# // CREATE SCENE //\n",
    "scene = Scene(root = False, atlas_name = 'allen_mouse_25um', inset = False, title = None, screenshots_folder = save_folder_thesis, plotter = None)\n",
    "\n",
    "# // ADD REGIONS AND CELLS//\n",
    "scene.add_brain_region(\"PAG\", alpha = 0.2, color = \"darkgoldenrod\", silhouette = None, hemisphere = \"both\")\n",
    "#scene.add_brain_region(\"SCm\", alpha = 0.1, color = \"olivedrab\", silhouette = None, hemisphere = \"both\")\n",
    "scene.add(Points(vgat_cells[column_names].values, name = \"vgat\", colors = \"#FF8080\", alpha = 1, radius = 20, res = 16)) # colour is #FF8080 in figures, but salmon is the same\n",
    "scene.add(Points(vglut2_cells[column_names].values, name = \"vglut2\", colors = \"#0F99B2\", alpha = 1, radius = 20, res = 16)) # colour is #0F99B2 in figures, but skyblue looks good here\n",
    "\n",
    "# // RENDER INTERACTIVELY //\n",
    "# Render interactively. You can press \"s\" to take a screenshot\n",
    "scene.render(interactive = True, camera = \"three_quarters\", zoom = 4) # cameras can be \"sagittal\", \"sagittal2\", \"frontal\", \"top\", \"top_side\", \"three_quarters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colouring cells by cell_type (VGAT or VGluT2), we will save the following screenshots:\n",
    "* Axes False, Zoom 4, Frontal Camera, sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "brainrender.settings.SHOW_AXES = False\n",
    "brainrender.settings.SCREENSHOT_SCALE = 10 # values >1 yield higher resolution screenshots\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\" # affects the look of rendered brain regions, values can be: [\"metallic\", \"plastic\", \"shiny\", \"glossy\", \"cartoon\"] and can be changed in interactive mode\n",
    "brainrender.settings.ROOT_COLOR = [0.4, 0.4, 0.4] # color of the overall brain model's actor (defaults to [0.8, 0.8, 0.8])\n",
    "brainrender.settings.ROOT_ALPHA = 0.2 # transparency of the overall brain model's actor (defaults to 0.2)\n",
    "save_folder_thesis = r\"D:\\Dropbox (UCL)\\Project_transcriptomics\\analysis\\PAG_scRNAseq_brainrender\\output\\figures_thesis_chapter_2\"\n",
    "\n",
    "# Create a variable containing the XYZ coordinates of the cells.\n",
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "\n",
    "# Color cells according to whether they are excitatory or inhibitory:\n",
    "vgat_cells = pag_data.loc[pag_data[\"cell.type\"] == \"VGAT\"]\n",
    "vglut2_cells =  pag_data.loc[pag_data[\"cell.type\"] == \"VGluT2\"]\n",
    "\n",
    "# // CREATE SCENE //\n",
    "scene = Scene(root = False, atlas_name = 'allen_mouse_25um', inset = False, title = None, screenshots_folder = save_folder_thesis, plotter = None)\n",
    "\n",
    "# // ADD REGIONS AND CELLS//\n",
    "pag = scene.add_brain_region(\"PAG\", alpha = 0.2, color = \"darkgoldenrod\", silhouette = None, hemisphere = \"both\")\n",
    "#scene.add_brain_region(\"SCm\", alpha = 0.1, color = \"olivedrab\", silhouette = None, hemisphere = \"both\")\n",
    "scene.add(Points(vgat_cells[column_names].values, name = \"vgat\", colors = \"#FF8080\", alpha = 1, radius = 20, res = 16)) # colour is #FF8080 in figures, but salmon is the same\n",
    "scene.add(Points(vglut2_cells[column_names].values, name = \"vglut2\", colors = \"#0F99B2\", alpha = 1, radius = 20, res = 16)) # colour is #0F99B2 in figures, but skyblue looks good here\n",
    "\n",
    "# // SLICE SCENE //\n",
    "slice_start = pag.centerOfMass() + np.array([-150, 0, 0]) # X microns from center of mass towards the nose (if positive) or cerebellum (if negative)\n",
    "slice_end = pag.centerOfMass() + np.array([+800, 0, 0]) # X microns from center of mass towards the nose (if adding) or cerebellum (if subtracting)\n",
    "\n",
    "for p, n in zip((slice_start, slice_end), (1, -1)):\n",
    "    plane = scene.atlas.get_plane(pos = p, norm = (n, 0, 0))\n",
    "    scene.slice(plane, actors = pag, close_actors = True)\n",
    "\n",
    "# // RENDER INTERACTIVELY //\n",
    "# Render interactively. You can press \"s\" to take a screenshot\n",
    "scene.render(interactive = True, camera = \"frontal\", zoom = 4) # cameras can be \"sagittal\", \"sagittal2\", \"frontal\", \"top\", \"top_side\", \"three_quarters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colouring cells by PAG subdivision, we will save the following screenshots:\n",
    "* Axes False, Zoom 4, Top Camera\n",
    "* Axes False, Zoom 4, Sagittal Camera\n",
    "* Axes False, Zoom 4, Three quarters Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "brainrender.settings.SHOW_AXES = False # Set this back to False\n",
    "brainrender.settings.SCREENSHOT_SCALE = 10 # values >1 yield higher resolution screenshots\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\" # affects the look of rendered brain regions, values can be: [\"metallic\", \"plastic\", \"shiny\", \"glossy\", \"cartoon\"] and can be changed in interactive mode\n",
    "brainrender.settings.ROOT_COLOR = [0.4, 0.4, 0.4] # color of the overall brain model's actor (defaults to [0.8, 0.8, 0.8])\n",
    "brainrender.settings.ROOT_ALPHA = 0.2 # transparency of the overall brain model's actor (defaults to 0.2)\n",
    "save_folder_thesis = r\"D:\\Dropbox (UCL)\\Project_transcriptomics\\analysis\\PAG_scRNAseq_brainrender\\output\\figures_thesis_chapter_2\"\n",
    "\n",
    "# Create a variable containing the XYZ coordinates of the cells.\n",
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "\n",
    "# Color cells according to their subdivision:\n",
    "dmpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"dmpag\"]\n",
    "dlpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"dlpag\"]\n",
    "lpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"lpag\"]\n",
    "vlpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"vlpag\"]\n",
    "\n",
    "# // CREATE SCENE //\n",
    "scene = Scene(root = False, atlas_name = 'allen_mouse_25um', inset = False, title = None, screenshots_folder = save_folder_thesis, plotter = None)\n",
    "\n",
    "# // ADD REGIONS AND CELLS//\n",
    "scene.add_brain_region(\"PAG\", alpha = 0.2, color = \"darkgoldenrod\", silhouette = None, hemisphere = \"both\")\n",
    "#scene.add_brain_region(\"SCm\", alpha = 0.1, color = \"olivedrab\", silhouette = None, hemisphere = \"both\")\n",
    "scene.add(Points(dmpag_cells[column_names].values, name = \"dmpag\", colors = \"cornflowerblue\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(dlpag_cells[column_names].values, name = \"dlpag\", colors = \"darkorange\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(lpag_cells[column_names].values, name = \"lpag\", colors = \"forestgreen\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(vlpag_cells[column_names].values, name = \"vlpag\", colors = \"firebrick\", alpha = 1, radius = 20, res = 16))\n",
    "\n",
    "# // RENDER INTERACTIVELY //\n",
    "# Render interactively. You can press \"s\" to take a screenshot\n",
    "scene.render(interactive = True, camera = \"three_quarters\", zoom = 4) # choose one of the cameras: sagittal, sagittal2, frontal, top, top_side, three_quarters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colouring cells by PAG subdivision, we will save the following screenshots:\n",
    "* Axes False, Zoom 4, Frontal Camera, sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWindow(None)  # <- this will make your scene popup\n",
    "brainrender.settings.SHOW_AXES = False # Set this back to False\n",
    "brainrender.settings.SCREENSHOT_SCALE = 10 # values >1 yield higher resolution screenshots\n",
    "brainrender.settings.SHADER_STYLE = \"cartoon\" # affects the look of rendered brain regions, values can be: [\"metallic\", \"plastic\", \"shiny\", \"glossy\", \"cartoon\"] and can be changed in interactive mode\n",
    "brainrender.settings.ROOT_COLOR = [0.4, 0.4, 0.4] # color of the overall brain model's actor (defaults to [0.8, 0.8, 0.8])\n",
    "brainrender.settings.ROOT_ALPHA = 0.2 # transparency of the overall brain model's actor (defaults to 0.2)\n",
    "save_folder_thesis = r\"D:\\Dropbox (UCL)\\Project_transcriptomics\\analysis\\PAG_scRNAseq_brainrender\\output\\figures_thesis_chapter_2\"\n",
    "\n",
    "# Create a variable containing the XYZ coordinates of the cells.\n",
    "column_names = [\"CCF.AllenAP\", \"CCF.AllenDV\", \"CCF.AllenML\"] # name of the columns containing the CCF coordinates\n",
    "\n",
    "# Color cells according to their subdivision:\n",
    "dmpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"dmpag\"]\n",
    "dlpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"dlpag\"]\n",
    "lpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"lpag\"]\n",
    "vlpag_cells = pag_data.loc[pag_data[\"PAG.area\"] == \"vlpag\"]\n",
    "\n",
    "# // CREATE SCENE //\n",
    "scene = Scene(root = False, atlas_name = 'allen_mouse_25um', inset = False, title = None, screenshots_folder = save_folder_thesis, plotter = None)\n",
    "\n",
    "# // ADD REGIONS AND CELLS//\n",
    "pag = scene.add_brain_region(\"PAG\", alpha = 0.2, color = \"darkgoldenrod\", silhouette = None, hemisphere = \"both\")\n",
    "#scene.add_brain_region(\"SCm\", alpha = 0.1, color = \"olivedrab\", silhouette = None, hemisphere = \"both\")\n",
    "scene.add(Points(dmpag_cells[column_names].values, name = \"dmpag\", colors = \"cornflowerblue\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(dlpag_cells[column_names].values, name = \"dlpag\", colors = \"darkorange\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(lpag_cells[column_names].values, name = \"lpag\", colors = \"forestgreen\", alpha = 1, radius = 20, res = 16))\n",
    "scene.add(Points(vlpag_cells[column_names].values, name = \"vlpag\", colors = \"firebrick\", alpha = 1, radius = 20, res = 16))\n",
    "\n",
    "# // SLICE SCENE //\n",
    "slice_start = pag.centerOfMass() + np.array([-150, 0, 0]) # X microns from center of mass towards the nose (if positive) or cerebellum (if negative)\n",
    "slice_end = pag.centerOfMass() + np.array([+800, 0, 0]) # X microns from center of mass towards the nose (if adding) or cerebellum (if subtracting)\n",
    "\n",
    "for p, n in zip((slice_start, slice_end), (1, -1)):\n",
    "    plane = scene.atlas.get_plane(pos = p, norm = (n, 0, 0))\n",
    "    scene.slice(plane, actors = pag, close_actors = True)\n",
    "\n",
    "# // RENDER INTERACTIVELY //\n",
    "# Render interactively. You can press \"s\" to take a screenshot\n",
    "scene.render(interactive = True, camera = \"frontal\", zoom = 4) # choose one of the cameras: sagittal, sagittal2, frontal, top, top_side, three_quarters"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "edf1f591ec7fb62cf36894aca142f45115e1c983ebc09e8358aac16eee7e4b37"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('brainrender': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
